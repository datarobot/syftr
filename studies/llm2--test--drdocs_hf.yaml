dataset:
  description: The dataset contains comprehensive information about DataRobot, including
    its API, documentation, examples, key features, platform architecture, integrations,
    setup guides, data handling, feature engineering, EDA tools, automated machine
    learning, model management, deployment options, monitoring, REST API, batch predictions,
    real-time scoring, custom recipes, retraining, lifecycle management, bias detection,
    explainability, diagnostics, cross-validation, leaderboard insights, time series
    modeling, data governance, security, user roles, Python/R usage, custom blueprints,
    external model integration, Docker deployments, API reference, BI tool integration,
    workflow automation, multimodal modeling, NLP, image recognition, hyperparameter
    tuning, performance optimization, resource management, parallel processing, drift
    detection, retraining triggers, industry use cases, tutorials, case studies, common
    issues, debugging tips, FAQs, support access, community resources, and release
    notes.
  eval_user_template: '

    ## User Query

    {query}


    ## Reference Answer

    {reference_answer}


    ## Generated Answer

    {generated_answer}

    '
  load_examples_timeout_s: 3600
  load_grounding_data_timeout_s: 3600
  partition_map:
    holdout: holdout
    sample: sample
    test: test
    train: train
  storage_partitions:
  - sample
  - train
  - test
  - holdout
  xname: drdocs_hf
evaluation:
  eval_system_template: "\nYou are an expert evaluation system for a question answering\
    \ chatbot.\n\nYou are given the following information:\n- a user query, and\n\
    - a reference answer\n- a generated answer\n\nYour job is to judge the relevance\
    \ and correctness of the generated answer.\n\nOutput a syntactically correct JSON\
    \ string that contains a 'score' field that represents a holistic evaluation and\
    \ a 'reasoning' field that explains the score.\n\nFollow these guidelines for\
    \ scoring:\n- Your score has to be between 1 and 5, where 1 is the worst and 5\
    \ is the best.\n- The generated answer is correct if it is in agreement with the\
    \ reference answer and incorrect otherwise.\n- If the generated answer is not\
    \ relevant to the user query, you should give a score of 1.\n- If the generated\
    \ answer is relevant but contains mistakes, you should give a score between 2\
    \ and 3.\n- If the generated answer is relevant and fully correct, you should\
    \ give a score between 4 and 5.\n\nExample Response:\n{\n  \"reasoning\": \"The\
    \ generated answer has the exact same metrics as the reference answer, but it\
    \ is not as concise.\"\n  \"score\": 4.0,\n}\n"
  eval_type: correctness
  llm_names:
  - gpt-4o-mini
  min_reporting_success_rate: 0.5
  mode: random
  raise_on_exception: false
  score_threshold: 4.0
  use_tracing_metrics: false
name: llm2--test--drdocs_hf
optimization:
  baselines: []
  baselines_cycle_llms: true
  blocks:
  - components:
    - rag_retriever
    - splitter
    - additional_context
    - few_shot_retriever
    - hyde
    - critique_rag_agent
    - lats_rag_agent
    - react_rag_agent
    - rag_mode
    - reranker
    - response_synthesizer
    - sub_question_rag
    - template_name
    name: global
    num_trials: 3000
  cpus_per_trial: 1
  embedding_device: null
  gpus_per_trial: 0.0
  max_concurrent_trials: 100
  max_eval_failure_rate: 0.5
  max_trial_cost: 40.0
  method: expanding
  num_eval_batch: 5
  num_eval_samples: 50
  num_prompt_optimization_batch: 50
  num_random_trials: 100
  num_retries_unique_params: 100
  num_trials: 3000
  num_warmup_steps_costout: 2
  num_warmup_steps_pareto: 30
  num_warmup_steps_timeout: 3
  obj1_zscore: 1.645
  obj2_zscore: 1.645
  objective_1_name: accuracy
  objective_2_name: p80_time
  pareto_eval_success_rate: 0.9
  pareto_pruner_success_rate: 0.9
  raise_on_failed_trial: false
  raise_on_invalid_baseline: false
  rate_limiter_max_coros: 10
  rate_limiter_period: 60
  sampler: tpe
  seeder_timeout: null
  shuffle_baselines: true
  shuffle_blocks: false
  skip_existing: true
  use_agent_baselines: false
  use_cost_pruner: true
  use_hf_embedding_models: false
  use_individual_baselines: false
  use_pareto_baselines: false
  use_pareto_pruner: true
  use_runtime_pruner: true
  use_toy_baselines: false
  use_variations_of_baselines: false
pareto: null
recreate_study: true
reuse_study: true
search_space:
  additional_context:
    num_nodes_max: 20
    num_nodes_min: 2
  additional_context_enabled:
  - false
  - true
  coa_rag_agent:
    enable_calculator:
    - false
    - true
  critique_rag_agent:
    critique_agent_llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
    reflection_agent_llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
    subquestion_engine_llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
    subquestion_response_synthesizer_llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
  few_shot_enabled:
  - false
  - true
  few_shot_retriever:
    embedding_models:
    - BAAI/bge-small-en-v1.5
    - thenlper/gte-large
    - mixedbread-ai/mxbai-embed-large-v1
    - WhereIsAI/UAE-Large-V1
    - avsolatorio/GIST-large-Embedding-v0
    - w601sxs/b1ade-embed
    - Labib11/MUG-B-1.6
    - sentence-transformers/all-MiniLM-L12-v2
    - sentence-transformers/paraphrase-multilingual-mpnet-base-v2
    - BAAI/bge-base-en-v1.5
    - baconnier/Finance2_embedding_small_en-V1.5
    - FinLang/finance-embeddings-investopedia
    - BAAI/bge-large-en-v1.5
    - Snowflake/snowflake-arctic-embed-l-v2.0
    - TencentBAC/Conan-embedding-v1
    - amentaphd/snowflake-artic-embed-l
    top_k:
      kmax: 20
      kmin: 2
      log: false
      step: 1
  hyde:
    llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
  hyde_enabled:
  - false
  - true
  lats_rag_agent:
    max_rollouts_max: 5
    max_rollouts_min: 2
    max_rollouts_step: 1
    num_expansions_max: 3
    num_expansions_min: 2
    num_expansions_step: 1
  non_search_space_params:
  - enforce_full_evaluation
  - retrievers
  rag_modes:
  - react_rag_agent
  - critique_rag_agent
  - sub_question_rag
  rag_retriever:
    embedding_models:
    - BAAI/bge-small-en-v1.5
    - thenlper/gte-large
    - mixedbread-ai/mxbai-embed-large-v1
    - WhereIsAI/UAE-Large-V1
    - avsolatorio/GIST-large-Embedding-v0
    - w601sxs/b1ade-embed
    - Labib11/MUG-B-1.6
    - sentence-transformers/all-MiniLM-L12-v2
    - sentence-transformers/paraphrase-multilingual-mpnet-base-v2
    - BAAI/bge-base-en-v1.5
    - baconnier/Finance2_embedding_small_en-V1.5
    - FinLang/finance-embeddings-investopedia
    - BAAI/bge-large-en-v1.5
    - Snowflake/snowflake-arctic-embed-l-v2.0
    - TencentBAC/Conan-embedding-v1
    - amentaphd/snowflake-artic-embed-l
    fusion:
      fusion_modes:
      - simple
      - reciprocal_rerank
      - relative_score
      - dist_based_score
    hybrid:
      bm25_weight_max: 0.9
      bm25_weight_min: 0.1
      bm25_weight_step: 0.1
    methods:
    - dense
    - sparse
    - hybrid
    query_decomposition:
      llm_config:
        llm_names:
        - gpt-oss-120b-low
        - gpt-oss-120b-medium
        - gpt-oss-120b-high
        - gpt-oss-20b-low
        - gpt-oss-20b-medium
        - gpt-oss-20b-high
        llm_temperature_max: 1.0
        llm_temperature_min: 0.0
        llm_temperature_step: 0.05
        llm_top_p_max: 1.0
        llm_top_p_min: 0.0
        llm_top_p_step: 0.05
        llm_use_reasoning:
        - true
        - false
        - null
      num_queries_max: 5
      num_queries_min: 2
      num_queries_step: 1
    query_decomposition_enabled:
    - true
    - false
    top_k:
      kmax: 10
      kmin: 1
      log: false
      step: 1
  react_rag_agent:
    subquestion_engine_llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
    subquestion_response_synthesizer_llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
  reranker:
    llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
    top_k:
      kmax: 128
      kmin: 2
      log: true
      step: 1
  reranker_enabled:
  - false
  - true
  response_synthesizer_llm_config:
    llm_names:
    - gpt-oss-120b-low
    - gpt-oss-120b-medium
    - gpt-oss-120b-high
    - gpt-oss-20b-low
    - gpt-oss-20b-medium
    - gpt-oss-20b-high
    llm_temperature_max: 1.0
    llm_temperature_min: 0.0
    llm_temperature_step: 0.05
    llm_top_p_max: 1.0
    llm_top_p_min: 0.0
    llm_top_p_step: 0.05
    llm_use_reasoning:
    - true
    - false
    - null
  splitter:
    chunk_max_exp: 10
    chunk_min_exp: 8
    chunk_overlap_frac_max: 0.5
    chunk_overlap_frac_min: 0.0
    chunk_overlap_frac_step: 0.05
    methods:
    - recursive
    - sentence
    - token
  sub_question_rag:
    subquestion_engine_llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
    subquestion_response_synthesizer_llm_config:
      llm_names:
      - gpt-oss-120b-low
      - gpt-oss-120b-medium
      - gpt-oss-120b-high
      - gpt-oss-20b-low
      - gpt-oss-20b-medium
      - gpt-oss-20b-high
      llm_temperature_max: 1.0
      llm_temperature_min: 0.0
      llm_temperature_step: 0.05
      llm_top_p_max: 1.0
      llm_top_p_min: 0.0
      llm_top_p_step: 0.05
      llm_use_reasoning:
      - true
      - false
      - null
  template_names:
  - default
  - concise
  - CoT
timeouts:
  embedding_max_time: 28800
  embedding_min_chunks_to_process: 100
  embedding_min_time_to_process: 120
  embedding_timeout_active: true
  eval_timeout: 36000
  onnx_timeout: 600
  single_eval_timeout: 7200
toy_mode: false
transfer_learning:
  embedding_model: BAAI/bge-large-en-v1.5
  max_fronts: 2
  max_total: 100
  studies: []
  success_rate: 0.9

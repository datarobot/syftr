{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors\n",
    "This simple notebook can be used list errors that happened while running various studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core import ultratb\n",
    "\n",
    "ultratb.VerboseTB.tb_highlight = \"bg:#3e0054\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getcwd().endswith(\"syftr\"):\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    print(f\"Changed working directory to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from syftr.optuna_helper import get_study_names\n",
    "\n",
    "INCLUDE_REGEX = [\n",
    "    # \".*llm2--thinking.*\",\n",
    "    \".*llm2--test.*\",\n",
    "]\n",
    "EXCLUDE_REGEX = []\n",
    "\n",
    "study_names = get_study_names(\n",
    "    include_regex=INCLUDE_REGEX,\n",
    "    exclude_regex=EXCLUDE_REGEX,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syftr.optuna_helper import get_failed_trials\n",
    "\n",
    "bad_trials = get_failed_trials(study_names=study_names)\n",
    "bad_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = bad_trials[[\n",
    "    \"user_attrs_metric_exception_class\", \n",
    "    \"user_attrs_metric_exception_message\", \n",
    "    \"user_attrs_metric_exception_stacktrace\", \n",
    "    \"user_attrs_metric_failed\"\n",
    "]].groupby(\n",
    "    by=[\"user_attrs_metric_exception_class\", \"user_attrs_metric_exception_message\"]\n",
    ").agg(\n",
    "    user_attrs_metric_exception_stacktrace=('user_attrs_metric_exception_stacktrace', 'first'),\n",
    "    user_attrs_metric_failed_count=('user_attrs_metric_failed', 'count')\n",
    ").reset_index()\n",
    "\n",
    "df_grouped = df_grouped.sort_values(by=\"user_attrs_metric_failed_count\", ascending=False)\n",
    "df_grouped = df_grouped[df_grouped[\"user_attrs_metric_exception_class\"] != \"TrialPruned\"]\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_grouped.iterrows():\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Number of failures for {row['user_attrs_metric_exception_class']}: {row['user_attrs_metric_failed_count']}\")\n",
    "    print(f\"Example stacktrace: {row['user_attrs_metric_exception_stacktrace']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syftr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ee3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "path = \"/Users/debadeepta.dey/datasets/barclays\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a61bc9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Split by Markdown Headers (Most intelligent for markdown)\n",
    "# This preserves the document structure and creates logical chunks\n",
    "\n",
    "def split_markdown_by_headers(document_content):\n",
    "    \"\"\"\n",
    "    Split markdown document by headers, preserving document structure\n",
    "    \"\"\"\n",
    "    # Define headers to split on (from h1 to h3)\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"), \n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "    \n",
    "    # Create the markdown header text splitter\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on,\n",
    "        strip_headers=False  # Keep headers in the chunks\n",
    "    )\n",
    "    \n",
    "    # Split the document\n",
    "    md_header_splits = markdown_splitter.split_text(document_content)\n",
    "    \n",
    "    return md_header_splits\n",
    "\n",
    "# # Example usage with your loaded documents\n",
    "# if docs:\n",
    "#     # Take the first document as example\n",
    "#     first_doc = docs[0]\n",
    "#     header_splits = split_markdown_by_headers(first_doc.page_content)\n",
    "    \n",
    "#     print(f\"Original document split into {len(header_splits)} chunks based on headers\")\n",
    "    \n",
    "#     # Display first few chunks\n",
    "#     for i, chunk in enumerate(header_splits[:3]):\n",
    "#         print(f\"\\n--- Chunk {i+1} ---\")\n",
    "#         print(f\"Content: {chunk.page_content[:200]}...\")\n",
    "#         print(f\"Metadata: {chunk.metadata}\")\n",
    "#         print(f\"Full length: {len(chunk.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c057368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Recursive Character Text Splitter (Good fallback)\n",
    "# This method is useful when documents don't have clear header structure\n",
    "\n",
    "def split_markdown_recursive(document_content, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split markdown using recursive character splitter with markdown-aware separators\n",
    "    \"\"\"\n",
    "    # Define separators that work well for markdown\n",
    "    markdown_separators = [\n",
    "        \"\\n\\n\",  # Double newline (paragraph breaks)\n",
    "        \"\\n\",    # Single newline\n",
    "        \" \",     # Space\n",
    "        \"\"       # Character level\n",
    "    ]\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=markdown_separators,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    # Split the document\n",
    "    chunks = text_splitter.split_text(document_content)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# # Example usage\n",
    "# if docs:\n",
    "#     first_doc = docs[0]\n",
    "#     recursive_chunks = split_markdown_recursive(\n",
    "#         first_doc.page_content, \n",
    "#         chunk_size=2048,  # Adjust based on your needs\n",
    "#         chunk_overlap=200\n",
    "#     )\n",
    "    \n",
    "#     print(f\"\\nRecursive splitting created {len(recursive_chunks)} chunks\")\n",
    "    \n",
    "#     # Display first few chunks\n",
    "#     for i, chunk in enumerate(recursive_chunks[:3]):\n",
    "#         print(f\"\\n--- Recursive Chunk {i+1} ---\")\n",
    "#         print(f\"Content: {chunk[:200]}...\")\n",
    "#         print(f\"Length: {len(chunk)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39fc45fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Hybrid Approach (Recommended)\n",
    "# Combine header-based splitting with recursive splitting for optimal results\n",
    "\n",
    "def smart_markdown_split(document_content, max_chunk_size=1500, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Smart markdown splitting that combines header-based and recursive approaches\n",
    "    \"\"\"\n",
    "    from langchain.schema import Document\n",
    "    \n",
    "    # First, try to split by headers\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"), \n",
    "        (\"###\", \"Header 3\"),\n",
    "        (\"####\", \"Header 4\"),\n",
    "    ]\n",
    "    \n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=headers_to_split_on,\n",
    "        strip_headers=False\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Split by headers first\n",
    "        header_splits = markdown_splitter.split_text(document_content)\n",
    "        \n",
    "        # If header splits are too large, further split them recursively\n",
    "        final_chunks = []\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=max_chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "            length_function=len,\n",
    "        )\n",
    "        \n",
    "        for doc in header_splits:\n",
    "            if len(doc.page_content) > max_chunk_size:\n",
    "                # Split large chunks further\n",
    "                sub_chunks = text_splitter.split_text(doc.page_content)\n",
    "                for i, sub_chunk in enumerate(sub_chunks):\n",
    "                    # Preserve metadata from header splitting\n",
    "                    new_metadata = doc.metadata.copy()\n",
    "                    new_metadata['sub_chunk'] = i\n",
    "                    final_chunks.append(Document(\n",
    "                        page_content=sub_chunk,\n",
    "                        metadata=new_metadata\n",
    "                    ))\n",
    "            else:\n",
    "                final_chunks.append(doc)\n",
    "                \n",
    "        return final_chunks\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Header splitting failed: {e}\")\n",
    "        # Fallback to recursive splitting\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=max_chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        )\n",
    "        chunks = text_splitter.split_text(document_content)\n",
    "        return [Document(page_content=chunk, metadata={}) for chunk in chunks]\n",
    "\n",
    "# # Example usage with the hybrid approach\n",
    "# if docs:\n",
    "#     first_doc = docs[0]\n",
    "#     smart_chunks = smart_markdown_split(\n",
    "#         first_doc.page_content,\n",
    "#         max_chunk_size=1200,\n",
    "#         chunk_overlap=150\n",
    "#     )\n",
    "    \n",
    "#     print(f\"\\nSmart splitting created {len(smart_chunks)} chunks\")\n",
    "    \n",
    "#     # Display statistics\n",
    "#     chunk_lengths = [len(chunk.page_content) for chunk in smart_chunks]\n",
    "#     print(f\"Average chunk length: {sum(chunk_lengths) / len(chunk_lengths):.0f} characters\")\n",
    "#     print(f\"Min chunk length: {min(chunk_lengths)} characters\")\n",
    "#     print(f\"Max chunk length: {max(chunk_lengths)} characters\")\n",
    "    \n",
    "#     # Display first few chunks with metadata\n",
    "#     for i, chunk in enumerate(smart_chunks[:3]):\n",
    "#         print(f\"\\n--- Smart Chunk {i+1} ---\")\n",
    "#         print(f\"Metadata: {chunk.metadata}\")\n",
    "#         print(f\"Content preview: {chunk.page_content[:200]}...\")\n",
    "#         print(f\"Length: {len(chunk.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7956566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 1/1: /Users/debadeepta.dey/datasets/barclays/rise-insights-report-making-data-count-with-ai-DIGITAL.md\n",
      "\n",
      "Total chunks created from all documents: 13\n",
      "Average chunk length: 9404 characters\n",
      "Chunk length range: 2316 - 10000 characters\n",
      "\n",
      "Chunks per source document:\n",
      "  /Users/debadeepta.dey/datasets/barclays/rise-insights-report-making-data-count-with-ai-DIGITAL.md: 13 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Utility function to process all your documents\n",
    "def process_all_documents(docs, output_method='smart', **kwargs):\n",
    "    \"\"\"\n",
    "    Process all loaded documents and return chunks\n",
    "    \n",
    "    Args:\n",
    "        docs: List of loaded documents\n",
    "        output_method: 'header', 'recursive', or 'smart'\n",
    "        **kwargs: Additional parameters for the splitting methods\n",
    "    \n",
    "    Returns:\n",
    "        List of all chunks with source document information\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "    \n",
    "    for doc_idx, doc in enumerate(docs):\n",
    "        print(f\"Processing document {doc_idx + 1}/{len(docs)}: {doc.metadata.get('source', 'unknown')}\")\n",
    "        \n",
    "        if output_method == 'header':\n",
    "            chunks = split_markdown_by_headers(doc.page_content)\n",
    "        elif output_method == 'recursive':\n",
    "            chunk_texts = split_markdown_recursive(doc.page_content, **kwargs)\n",
    "            chunks = [Document(page_content=text, metadata=doc.metadata.copy()) for text in chunk_texts]\n",
    "        elif output_method == 'smart':\n",
    "            chunks = smart_markdown_split(doc.page_content, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"output_method must be 'header', 'recursive', or 'smart'\")\n",
    "        \n",
    "        # Add source document information to each chunk\n",
    "        for chunk_idx, chunk in enumerate(chunks):\n",
    "            chunk.metadata['source_doc_index'] = doc_idx\n",
    "            chunk.metadata['chunk_index'] = chunk_idx\n",
    "            chunk.metadata['original_source'] = doc.metadata.get('source', 'unknown')\n",
    "            all_chunks.append(chunk)\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "# Process all your documents using the smart method\n",
    "all_processed_chunks = process_all_documents(\n",
    "    docs, \n",
    "    output_method='smart',  # Change to 'header' or 'recursive' if preferred\n",
    "    max_chunk_size=10000,\n",
    "    chunk_overlap=0 # deliberately set to 0\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal chunks created from all documents: {len(all_processed_chunks)}\")\n",
    "\n",
    "# Show summary statistics\n",
    "if all_processed_chunks:\n",
    "    chunk_lengths = [len(chunk.page_content) for chunk in all_processed_chunks]\n",
    "    print(f\"Average chunk length: {sum(chunk_lengths) / len(chunk_lengths):.0f} characters\")\n",
    "    print(f\"Chunk length range: {min(chunk_lengths)} - {max(chunk_lengths)} characters\")\n",
    "    \n",
    "    # Show distribution by source document\n",
    "    source_counts = {}\n",
    "    for chunk in all_processed_chunks:\n",
    "        source = chunk.metadata.get('original_source', 'unknown')\n",
    "        source_counts[source] = source_counts.get(source, 0) + 1\n",
    "    \n",
    "    print(f\"\\nChunks per source document:\")\n",
    "    for source, count in source_counts.items():\n",
    "        print(f\"  {source}: {count} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373120f0",
   "metadata": {},
   "source": [
    "## VLLM Configuration for RAGAS\n",
    "\n",
    "The configuration above connects RAGAS to your vLLM server. Here are some key points:\n",
    "\n",
    "1. **Base URL**: `http://localhost:8003/v1` - your vLLM endpoint\n",
    "2. **API Key**: Set to \"not-needed\" since vLLM typically doesn't require authentication\n",
    "3. **Model Name**: Replace `\"your-model-name\"` with the actual model you're serving\n",
    "4. **Temperature**: Controls randomness (0.1 is relatively deterministic)\n",
    "5. **Max Tokens**: Maximum response length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b55eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings.base import embedding_factory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Configure vLLM hosted LLM\n",
    "vllm_llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:8002/v1\",\n",
    "    api_key=\"asdf\",\n",
    "    model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",  # Replace with your actual model name\n",
    "    temperature=0.0,\n",
    "    max_tokens=32768,\n",
    ")\n",
    "\n",
    "# Wrap for RAGAS\n",
    "llm = LangchainLLMWrapper(vllm_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58fe900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing vLLM connection...\n",
      "✅ vLLM connection successful!\n",
      "Response: \n",
      "\n",
      "Hello! Got your test message.\n",
      "✅ RAGAS LLM wrapper configured correctly\n"
     ]
    }
   ],
   "source": [
    "# Test the vLLM connection\n",
    "print(\"Testing vLLM connection...\")\n",
    "\n",
    "try:\n",
    "    # Test the LLM directly\n",
    "    test_response = vllm_llm.invoke(\"Hello, this is a test. Please respond briefly.\")\n",
    "    print(f\"✅ vLLM connection successful!\")\n",
    "    print(f\"Response: {test_response.content}\")\n",
    "    \n",
    "    # Test with RAGAS wrapper\n",
    "    from ragas.llms.base import BaseRagasLLM\n",
    "    if isinstance(llm, BaseRagasLLM):\n",
    "        print(\"✅ RAGAS LLM wrapper configured correctly\")\n",
    "    else:\n",
    "        print(\"⚠️  RAGAS LLM wrapper might need adjustment\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error connecting to vLLM: {e}\")\n",
    "    print(\"Please check:\")\n",
    "    print(\"1. vLLM server is running\")\n",
    "    print(\"2. Model name is correct\")\n",
    "    print(\"3. No firewall blocking the connection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7108734",
   "metadata": {},
   "source": [
    "# vLLM Hosted Embedding Model Configuration\n",
    "\n",
    "Here's how to configure a vLLM hosted embedding model for use with RAGAS:\n",
    "\n",
    "## Option 1: Using OpenAI-compatible embedding endpoint\n",
    "If your vLLM server hosts an embedding model with OpenAI-compatible API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b31482f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "# import asyncio\n",
    "\n",
    "# # Try each configuration until one works\n",
    "# vllm_embeddings = OpenAIEmbeddings(\n",
    "#         base_url=\"http://localhost:8001/v1\",\n",
    "#         api_key=\"asdf\",\n",
    "#         model='thenlper/gte-large',\n",
    "#         tiktoken_enabled=False,  # Disable tiktoken for vLLM\n",
    "#     )\n",
    "\n",
    "# embedding_model = LangchainEmbeddingsWrapper(vllm_embeddings)\n",
    "\n",
    "# async def test_embedding_model(vllm_embeddings: OpenAIEmbeddings):\n",
    "#     \"\"\"Async function to test the embedding model\"\"\"\n",
    "    \n",
    "#     # Test with a simple text first\n",
    "#     print(\"testing query embedding...\")\n",
    "#     test_result = vllm_embeddings.embed_query(\"Risk management is crucial for financial institutions.\")\n",
    "#     print(f\"query embedding dimensions: {len(test_result)}\")\n",
    "\n",
    "#     # Test with texts\n",
    "#     print(\"testing text embedding...\")\n",
    "#     test_texts = [\n",
    "#         \"This is a test document about financial analysis.\",\n",
    "#         \"Machine learning models are used in banking.\",\n",
    "#         \"Risk management is crucial for financial institutions.\"\n",
    "#     ]\n",
    "#     test_results = vllm_embeddings.embed_documents(test_texts)\n",
    "#     print(f\"Text embedding dimensions: {len(test_results[0])} for {len(test_results)} texts\")\n",
    "    \n",
    "#     # If successful, wrap for RAGAS and test it through the wrapper\n",
    "#     embedding_model = LangchainEmbeddingsWrapper(vllm_embeddings)\n",
    "\n",
    "#     print(\"Testing wrapped embedding model query ...\")\n",
    "#     embedding_result = await embedding_model.embed_query(\"Risk management is crucial for financial institutions.\")\n",
    "#     print(f\"Wrapped query embedding dimensions: {len(embedding_result)}\")\n",
    "\n",
    "#     print(\"Testing wrapped embedding model text ...\")\n",
    "#     embedding_results = await embedding_model.embed_texts(test_texts, is_async=True)\n",
    "#     print(f\"Wrapped text embedding dimensions: {len(embedding_results[0])} for {len(embedding_results)} texts\")\n",
    "\n",
    "#     print(f\"✅ Successfully configured vLLM embedding model\")\n",
    "#     return embedding_model\n",
    "\n",
    "# # Run the async function\n",
    "# try:\n",
    "#     embedding_model = asyncio.run(test_embedding_model(vllm_embeddings))\n",
    "#     print(f\"🎉 Using vLLM embedding model successfully!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Failed with: {str(e)[:100]}...\")\n",
    "#     embedding_model = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66685102",
   "metadata": {},
   "source": [
    "# Option 2: local embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9123be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/yssyvkk54_b21htl90_2g_080000gp/T/ipykernel_46527/807525259.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  local_embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22206830978393555, 0.051233645528554916, -0.491749107837677, -0.4322299361228943, 0.5002784132957458, -0.2561419606208801, -0.22091081738471985, 0.11627580225467682, 0.4728822112083435, 0.08462154865264893, 0.3242437243461609, -0.19702470302581787, -0.36262261867523193, -0.2812041640281677, -0.36116212606430054, 0.08653219789266586, 0.08922451734542847, -0.16965575516223907, -0.39888814091682434, -0.2973982095718384, 0.6447439789772034, 0.7650296092033386, -0.6067692637443542, -0.3339347541332245, 0.3801654875278473, -0.3341101408004761, -0.16917163133621216, -0.010672621428966522, 0.13589155673980713, 0.7128159999847412, -0.6217780113220215, -0.042145416140556335, -0.07324082404375076, -1.0624228715896606, -0.01020888052880764, -0.7508808374404907, 0.5139471292495728, -0.9261746406555176, -0.4445686340332031, -0.7835230827331543, -0.4164794087409973, 0.0833824947476387, 0.30117857456207275, -0.637333333492279, -0.7911930084228516, 0.09582684934139252, -0.3917580246925354, 0.08683580905199051, 0.6413971185684204, -0.8161498308181763, -0.02510622888803482, 0.3480791747570038, 0.5102754831314087, 0.010825647972524166, 0.024440117180347443, -0.49215203523635864, 0.45990410447120667, 0.020236387848854065, -0.056113459169864655, 0.620966911315918, -0.263802707195282, 0.2514188885688782, 0.43374067544937134, -1.5778640508651733, -0.3432634174823761, -0.10514787584543228, 0.4252501130104065, -0.7035882472991943, 0.7603548169136047, -0.24159115552902222, -0.12211216986179352, 0.5205444097518921, 0.10612176358699799, -0.29616260528564453, -0.9526011347770691, 0.1380445957183838, -0.9346005916595459, -0.12144991010427475, 0.32955944538116455, 0.6389495730400085, -0.11909645795822144, 0.80478435754776, -1.0629146099090576, 0.09499762952327728, -0.2559436857700348, -0.3419335186481476, -0.041599392890930176, 0.16329579055309296, -0.7427644729614258, 0.4264370799064636, 1.4789419174194336, 0.953029215335846, 0.1947574019432068, -0.40775495767593384, 0.7413784265518188, -0.07727555930614471, 0.04623107612133026, 0.4576510488986969, 0.16363339126110077, 0.38255757093429565, 0.6922783851623535, 0.3602486848831177, -0.07548847049474716, 0.8179692625999451, -0.23670029640197754, -0.1635613739490509, -0.18866169452667236, -0.8018100261688232, -0.96413254737854, -0.3531401455402374, 0.00995999202132225, -0.05385060980916023, 0.579920768737793, 0.06017041206359863, -0.49051687121391296, 0.7909472584724426, 0.15073327720165253, 0.6010760068893433, -0.5779573321342468, -0.17494668066501617, 0.0852322056889534, 0.5269415378570557, -0.1334744244813919, -0.31674081087112427, 0.4833444654941559, -0.030565230175852776, -0.5749952793121338, 0.33473968505859375, 0.0004319101572036743, 0.45592737197875977, -0.18767769634723663, -0.8602790236473083, 0.3829115033149719, -0.0802556723356247, 0.09994492679834366, 0.7468171715736389, 0.11103043705224991, 0.6189877390861511, 0.49376949667930603, -0.24391292035579681, 0.9451703429222107, 0.13011273741722107, 0.5095144510269165, 1.255920648574829, -0.7403191924095154, 0.6105400919914246, -0.2897707521915436, 0.18060539662837982, -0.6257873773574829, -0.23152831196784973, -0.31635817885398865, 0.42520201206207275, -0.6913508176803589, 0.7072970867156982, -0.5001314878463745, 0.03753262013196945, -0.17148220539093018, 0.42012453079223633, 0.392981618642807, 0.1883641481399536, -0.611476480960846, 0.30196577310562134, 0.43094030022621155, 0.11945705115795135, -0.39281782507896423, 0.21264547109603882, 0.3656338155269623, 0.24542608857154846, 0.0846385806798935, 0.2507622241973877, 0.33082717657089233, 0.9564147591590881, -0.9108942747116089, 0.2504575550556183, -0.08718903362751007, 0.11290307343006134, -0.18700942397117615, -0.1247681975364685, 0.5808479189872742, 0.7902886867523193, -0.40303218364715576, -0.2600286602973938, -0.16773200035095215, 0.43643248081207275, -0.43649181723594666, 0.3036612272262573, 0.20779652893543243, -0.4620950520038605, -0.5630983710289001, -0.06565248221158981, -0.1545879989862442, 0.5325674414634705, -0.030392250046133995, 0.11382918059825897, 0.3787766993045807, 0.7037674188613892, -0.7097041606903076, 0.012877002358436584, -0.07430759817361832, -0.7057828307151794, -0.25471949577331543, 0.9276160597801208, -0.05897224694490433, -0.13378897309303284, 0.10329968482255936, -0.2711450755596161, 0.590972900390625, 0.7145387530326843, -0.9214826226234436, -0.5122234225273132, 0.7867801189422607, 0.19255970418453217, -0.5133690237998962, 0.33079585433006287, 0.04017431288957596, -0.574737548828125, -0.47399821877479553, 0.5004295110702515, -0.20272919535636902, 0.13311152160167694, 0.015913158655166626, 0.6636849045753479, 0.5761948227882385, 1.1156107187271118, 0.3925614356994629, -0.056861184537410736, -0.22298766672611237, 0.713234007358551, -0.09035839140415192, -0.6036624312400818, -0.17358636856079102, 0.006314091384410858, -0.4152955114841461, 1.1463758945465088, -0.031577859073877335, 0.5993724465370178, 0.7650524377822876, 0.9349228739738464, -0.1082908883690834, 0.06031068041920662, -0.010153815150260925, 0.23446504771709442, 1.292172908782959, 0.5910046100616455, 0.22069312632083893, 0.018930751830339432, 0.8708239793777466, -0.06955023854970932, -0.4228111803531647, 0.34676605463027954, -0.08359949290752411, 0.4039374887943268, 0.5903169512748718, 0.5580243468284607, -0.1924194097518921, 0.14943927526474, 0.018999025225639343, 0.3507327437400818, -0.6487327814102173, -0.02605743706226349, 0.018284596502780914, -0.710110068321228, 0.24816735088825226, -0.568193256855011, -0.28102582693099976, -0.20176838338375092, 0.6107132434844971, 0.4522159993648529, -0.2823016047477722, -1.3116886615753174, -0.05152880400419235, -1.0032899379730225, -0.2586948573589325, 0.25646743178367615, -0.30640578269958496, 0.1625765562057495, 0.8328151106834412, -0.31409648060798645, 0.5652180910110474, -0.8017776012420654, 0.21610838174819946, -0.04218677431344986, -1.3392473459243774, 0.29432472586631775, -0.27536314725875854, 0.13420593738555908, -0.08812867105007172, 0.2345127910375595, 0.302409827709198, 0.6412661671638489, 0.02387409098446369, 0.23204033076763153, -0.3081594407558441, -0.19499143958091736, -0.19224198162555695, -0.1255355179309845, -0.6842144727706909, -0.6973284482955933, -0.48616722226142883, -0.34260624647140503, -0.008067015558481216, 0.43065735697746277, 0.2141490876674652, 0.20145292580127716, -0.24903763830661774, -0.4520299732685089, 0.740027904510498, -0.45582491159439087, 0.36073970794677734, 0.5021517872810364, -0.011143525131046772, 0.6358915567398071, -0.11866289377212524, -0.1446155458688736, -0.6916542053222656, 0.8480026125907898, 0.34276825189590454, 0.3864991366863251, -0.27098751068115234, 0.01104971393942833, -0.30847612023353577, -0.24240127205848694, -0.6362023949623108, -1.2759771347045898, -0.2525508999824524, 0.814935564994812, -0.03627192974090576, -0.5185859203338623, 0.9258391857147217, -1.267395257949829, -0.8815793991088867, -0.6668513417243958, 0.2209962159395218, 0.10606691986322403, 0.5050491690635681, 0.44652992486953735, 0.7180901765823364, 0.5007623434066772, -0.1082463189959526, -0.552284300327301, 0.7648987174034119, -0.7459015250205994, -0.061985909938812256, 0.40404069423675537, -0.8538017272949219, 0.15434351563453674, -0.37091386318206787, -0.7514662742614746, -0.0942593440413475, 0.2271822690963745, -0.1176825538277626, 0.4039178490638733, -0.19903744757175446, 0.39622700214385986, -0.01838812232017517, 0.36763426661491394, -0.6811727285385132, 0.4131803810596466, 0.24000674486160278, -0.48281192779541016, 0.4657175540924072, 0.9786943197250366, 0.37565070390701294, -1.4095298051834106, 0.14575780928134918, -1.5140033960342407, -1.2854968309402466, 0.6898131966590881, 0.8123413920402527, -1.1031156778335571, 0.23612993955612183, -0.7337303161621094, -0.21338340640068054, -0.2557915151119232, -1.0366368293762207, -0.9773082137107849, 0.26225200295448303, -0.7594544887542725, 0.5674275755882263, -1.0628160238265991, 0.3222675025463104, -0.027141325175762177, 0.015454299747943878, 0.7223178744316101, 0.6297519207000732, 0.07065580040216446, -0.6332762837409973, -0.40598154067993164, 0.30175191164016724, -0.013400204479694366, -0.1525755524635315, -0.3171244263648987, 0.4050084352493286, -0.028741247951984406, -1.2786402702331543, -0.44408202171325684, 0.0814252495765686, 0.15443848073482513, 0.43814074993133545, -0.5226649045944214, 0.9359182119369507, 0.1445578932762146, 0.7588184475898743, 0.5867152214050293, -1.0921167135238647, 0.31939321756362915, -0.3776671588420868, 0.3246181309223175, 0.41631820797920227, -0.00887889415025711, -0.7263317704200745, 1.295341968536377, -0.08899460732936859, 0.7128781080245972, 1.7156736850738525, -0.6387289762496948, -0.15874388813972473, 0.4389239549636841, 0.2161063402891159, 0.4482286870479584, -0.658261239528656, -0.5197750329971313, -0.37222883105278015, 0.24936100840568542, 0.6853222846984863, 0.1384570151567459, -0.07979975640773773, 0.15102815628051758, 1.1881568431854248, 0.20890505611896515, -0.2474147528409958, -0.984214186668396, -0.08531317114830017, -0.17781323194503784, -0.22325417399406433, 0.31801506876945496, 0.5755155682563782, -0.5036711692810059, 0.5869247317314148, -0.7645082473754883, 1.0461950302124023, 0.6504847407341003, -0.20249351859092712, 0.0020838589407503605, -0.22445939481258392, -0.37094515562057495, -0.08948037028312683, -0.11593122780323029, -0.0971602126955986, -0.34310832619667053, -0.0446130707859993, -0.560699462890625, 0.3856556713581085, 0.06115186959505081, -0.21990826725959778, -0.1989501565694809, -0.1891718953847885, 0.02213294804096222, 0.07827059179544449, 0.03921585530042648, -0.5514841675758362, -0.2527831196784973, 0.8617922067642212, -0.13110125064849854, -0.20128662884235382, 1.037947654724121, -0.04265913367271423, 0.4678521454334259, 0.5466118454933167, 1.0674662590026855, 0.07827024161815643, 0.8669664263725281, 0.42746269702911377, -0.5992133021354675, 0.6819144487380981, -0.2565828561782837, 0.4180993139743805, -0.09419139474630356, -0.3063737452030182, 0.48054561018943787, -0.45660993456840515, -0.3482947051525116, -0.21240220963954926, -0.29417604207992554, -0.29830536246299744, -1.0606456995010376, -0.14861918985843658, -0.0547468438744545, 0.04813038557767868, -0.12510336935520172, -0.17466428875923157, 0.2294330596923828, -0.7129305601119995, -0.5552430748939514, 0.5729092955589294, 0.1508452296257019, -1.0147731304168701, 0.5306758284568787, -0.14270150661468506, 0.1814926564693451, 0.4666381776332855, 0.4753538966178894, -0.4851340353488922, -0.1640114188194275, -0.7283827662467957, -0.25565963983535767, -0.7787041068077087, 0.6077859997749329, -0.261788547039032, -0.02850327268242836, -0.2775169014930725, 0.3121562600135803, -0.271651953458786, 0.23871487379074097, -0.11868853867053986, -0.1356348991394043, 0.04896868020296097, 0.6431950926780701, -0.2079540640115738, 0.046006180346012115, 0.8164235353469849, -1.541909098625183, -0.5494663119316101, 0.6098678112030029, 0.32153987884521484, 0.45893147587776184, 0.8873024582862854, -0.2925199270248413, -0.004979402758181095, 0.24975627660751343, 0.2772303819656372, 0.21372418105602264, -0.157757967710495, -0.7996281385421753, -0.032356515526771545, -0.08211791515350342, 0.2764214277267456, -0.11974275857210159, -0.10908538103103638, 0.2584574818611145, -0.25631019473075867, 0.6360591053962708, 0.031041603535413742, -0.5721611380577087, -0.8286163210868835, -0.034722477197647095, 0.6156883835792542, 1.2981756925582886, -0.6226435303688049, 0.7592233419418335, 0.05466751381754875, 0.19871504604816437, 0.41985419392585754, -0.39068862795829773, -1.118241548538208, -0.4035235047340393, 0.043802715837955475, 0.1647946536540985, 0.25339069962501526, 0.6945303082466125, -0.16637933254241943, 0.6562715172767639, -0.7090114951133728, -0.5814447999000549, 0.04399368166923523, -0.46232980489730835, -0.4791311025619507, -0.39607474207878113, 0.9434999823570251, -0.651072084903717, -0.27703240513801575, -0.203446164727211, 0.5483949184417725, 1.0088896751403809, -0.25865939259529114, -0.2172859162092209, -0.7508636713027954, -0.025567831471562386, -0.5114839673042297, -0.3128647208213806, 0.06309446692466736, -0.4710352420806885, -0.34758010506629944, -0.17412987351417542, 0.4773363769054413, -0.42678558826446533, 0.5239182114601135, 0.7056219577789307, 0.40053969621658325, -0.8464168310165405, -0.73720383644104, 0.27641546726226807, -0.20270031690597534, -0.252881795167923, -0.780498206615448, -0.9208337068557739, -1.1944966316223145, -0.6646004319190979, -0.2649098336696625, -0.5816936492919922, -0.8729163408279419, -0.05607964098453522, 0.5642736554145813, 0.5568316578865051, 0.7801082730293274, 0.10713938623666763, -0.5616562366485596, -0.8037165999412537, 0.7066240310668945, 0.8743737936019897, 0.29266679286956787, 1.1542059183120728, 0.23777170479297638, 0.026892662048339844, 0.6302958726882935, -0.19847196340560913, 0.07536302506923676, -0.8499016761779785, 0.38230985403060913, -0.5627231001853943, 0.0626152753829956, 0.8949264883995056, 1.5403878688812256, -0.6243395805358887, -0.5547260046005249, -0.10128147900104523, 0.12849721312522888, -0.3069422245025635, -0.061402931809425354, -0.2914310395717621, -0.7957074046134949, -1.1769731044769287, 0.06351956725120544, 0.6681305766105652, 0.06846815347671509, 0.23317782580852509, -0.2066756635904312, -0.014857541769742966, -0.8030973076820374, 0.6748805046081543, 0.42420321702957153, -0.8305175304412842, -0.14418913424015045, -1.269805908203125, -0.4826354384422302, -0.29452192783355713, 0.37696608901023865, -0.15359511971473694, -0.2019418478012085, 0.11883046478033066, 0.21170149743556976, 0.4499402642250061, 0.32189297676086426, -0.4234473705291748, -0.41362273693084717, -0.14334769546985626, 0.2764754593372345, -0.7711341977119446, -0.2757917642593384, 0.34207722544670105, 0.2053879201412201, 0.4910341203212738, -0.8184255361557007, -0.7768811583518982, 1.2147395610809326, 0.954680323600769, -0.3844239115715027, 0.2798362374305725, -1.0552504062652588, -0.5727007985115051, -0.7121825218200684, -0.9242633581161499, -0.37718522548675537, -0.301349401473999, 0.22187042236328125, 0.23794937133789062, 0.08720408380031586, -0.25507649779319763, 0.41910961270332336, 0.022886604070663452, 0.5998625159263611, -0.5944249033927917, 0.8525524139404297, -0.19529837369918823, -0.9557707905769348, -0.10399741679430008, -0.3055076003074646, -0.34845206141471863, -0.04063227400183678, 0.03803376480937004, 0.3383771479129791, -1.0549300909042358, 0.9997596144676208, 0.4898747503757477, 0.17816725373268127, -0.3527342975139618, -0.4685550332069397, -0.29975828528404236, 1.0553390979766846, 0.563946008682251, -0.2424485981464386, 0.3357105851173401, -0.6263434290885925, -0.015409361571073532, 0.6546840071678162, -0.8105987906455994, 0.09915933012962341, -0.1794392317533493, -0.09397747367620468, 0.43894827365875244, -0.3093910217285156, -0.4455314874649048, -0.3719451427459717, -0.706433892250061, 0.36237478256225586, 0.8723920583724976, 0.34547024965286255, -0.3342101573944092, 0.10078072547912598, 0.5211973786354065, 0.37258610129356384, 0.19500891864299774, 0.7663209438323975, 0.42451441287994385, 0.34050995111465454, -0.062398817390203476, -0.6188636422157288, 0.946000337600708, -0.32670897245407104, -0.033793121576309204, 0.7378658652305603, -0.3581313490867615, 0.5424721837043762, -0.36526280641555786, 0.4598191976547241, -0.8156595230102539, -0.5662054419517517, -1.2252010107040405, -0.2930842936038971, 0.4530240595340729, 0.18438459932804108, 0.7042012214660645, 0.27837175130844116, -0.04303968697786331, -0.7966680526733398, -0.3919539451599121, 0.002221032977104187, -0.8174437284469604, -0.6404602527618408, 0.4818393588066101, 0.08010005205869675, 0.12037386000156403, -0.4302947521209717, -0.08520890027284622, 0.5163129568099976, 0.130588561296463, 0.4698774516582489, -0.2883262038230896, -0.28287166357040405, 0.16163599491119385, -0.420818567276001, -0.2646302580833435, -0.15854531526565552, -0.1143244057893753, 0.6597723364830017, -0.24875786900520325, -0.3467556834220886, -0.25884008407592773, -0.3937869369983673, 0.6891432404518127, -0.6319320201873779, 0.4417627453804016, 0.09756606072187424, 0.11538080126047134, -0.3119676113128662, 0.38487866520881653, 0.059830792248249054, -0.2533300220966339, 0.7183233499526978, -0.5108522176742554, 0.7558802366256714, -0.6503502130508423, 0.5191322565078735, 0.6491400599479675, 0.006115313619375229, 0.5202792286872864, 0.5932022929191589, 0.4061599373817444, -0.36202314496040344, 0.1043744683265686, 0.0634131208062172, 0.6371746063232422, -0.19093655049800873, -0.04131127521395683, 0.010666681453585625, 0.8668831586837769, 0.40003135800361633, 0.15795038640499115, -0.06409469991922379, -0.011622752994298935, 0.9866329431533813, 0.3260645866394043, 0.5567108988761902, 0.5367836356163025, 0.5314672589302063, -0.4104536473751068, 0.5584492087364197, -0.48865431547164917, 0.01132892444729805, -0.18405358493328094, 0.0483100563287735, 0.5007781386375427, -0.20864588022232056, -0.3894909620285034, -0.5400816202163696, 0.4535323977470398, 0.3386614918708801, 0.1336187869310379, 0.7032814025878906, 0.12380758672952652, -0.784544825553894, -0.33869028091430664, 0.952115535736084, 0.21288099884986877, -0.4362486004829407, -0.3039332628250122, 0.3608500361442566, 0.12496694177389145, 0.2990568280220032, 0.6239490509033203, -0.21996989846229553, -0.8219749331474304, -0.3550947308540344, 0.8126183152198792, 0.45749950408935547, -0.03656564652919769, 0.29292207956314087, -0.07314600795507431, 0.14209941029548645, -1.1075401306152344, 0.18038755655288696, 0.7969664335250854, -0.24063915014266968, -0.8047633767127991, -0.5673301219940186, 0.49321669340133667, 0.13373695313930511, 0.2664448916912079, 0.45545172691345215, -0.14854022860527039, -0.2022688090801239, 0.6770399808883667, -0.3456427752971649, 0.47716450691223145, -0.15163227915763855, 0.0057330019772052765, -0.5619528889656067, 0.21276679635047913, 0.018115054816007614, -0.4351975917816162, -0.5722365975379944, 0.09164606779813766, -0.26240187883377075, -1.0702811479568481, -0.3693225681781769, -1.1470122337341309, 0.14067305624485016, -0.7658770084381104, -0.1761651337146759, 0.06443196535110474, 0.6585835218429565, 0.35344377160072327, -0.37176746129989624, -0.17355230450630188, 1.067296028137207, -0.49269434809684753, 0.1338992416858673, 0.2038155347108841, 1.0897144079208374, -0.3451952040195465, 0.008046917617321014, -0.1451716423034668, -0.17546436190605164, -0.4482959806919098, -1.6924405097961426, 0.42474564909935, -0.14168372750282288, -0.4902358651161194, -0.393586665391922, -0.5183358192443848, -0.1902427226305008, 0.04762764647603035, 0.18185210227966309, -0.7253889441490173, -0.5491524338722229, 0.7185472249984741, -0.3220268189907074, 0.0875648632645607, -0.32003048062324524, 0.3651386499404907, 0.8684136271476746, 0.7556067705154419, -0.30974259972572327, 0.1822352111339569, 0.03716493397951126, -0.22185328602790833, -0.5294713973999023, -0.3678458333015442, 0.240099236369133, -0.7082284092903137, -0.27487167716026306, -0.4180818498134613, 0.030818363651633263, 0.08225008100271225, -0.17230528593063354, 0.405423104763031, 0.9079499840736389, 0.00986567884683609, -0.30923113226890564, -0.9320497512817383, -0.49153387546539307, -0.7015489339828491, -0.3087596297264099, -0.5576617121696472, 0.9133711457252502, -0.6942664384841919, 0.5310744643211365, -0.06692957878112793, -1.038590908050537, 4.100334644317627, 0.8438158631324768, 0.9235959053039551, -0.21024349331855774, 0.9873863458633423, 0.7146062254905701, 0.21386760473251343, -0.304068386554718, 0.30316102504730225, -0.5781848430633545, 0.6879402995109558, 0.3536127209663391, 0.754141628742218, 0.17074106633663177, 0.16698692739009857, 0.6457467675209045, -0.37881964445114136, 0.10862898826599121, -0.030446723103523254, -0.701384961605072, -0.6808823347091675, 0.3019167184829712, 0.08129802346229553, -0.1093926727771759, -0.5506486296653748, 0.3386276662349701, 0.19801969826221466, 0.06162708252668381, 0.09209470450878143, -0.42152151465415955, 0.1770888864994049, 0.7634785175323486, 0.13174980878829956, 0.20282797515392303, -0.33814537525177, 0.5972028970718384, -0.10285200923681259, -1.0401620864868164, -0.12240778654813766, 0.8530306816101074, -0.43494394421577454, -0.21397565305233002, -0.195002481341362, 0.4769340753555298, -0.23088987171649933, 0.29098963737487793, -0.469237357378006, 0.11785417050123215, -0.005782098509371281, -0.41697198152542114, 0.6593033671379089, -0.8729000091552734, 0.7447889447212219, -0.9121420383453369, -0.08314342051744461, 0.2825757563114166, 0.49081942439079285, 0.07860018312931061, -0.19237297773361206, -0.6701946258544922, 0.10204624384641647, -0.04747474193572998, -0.37288832664489746, -0.3055190443992615, -0.6584333777427673, 0.6091163754463196, 1.0099966526031494, 0.4219493865966797, -0.5718149542808533, 0.06360625475645065, -0.566274106502533, -0.6851110458374023, -0.2171037495136261, -0.605509340763092, 0.27336370944976807, 0.11418013274669647, -0.4348917007446289, 0.1677711009979248, -0.3759535551071167, 0.3761771023273468, 0.5144508481025696, -0.2185847908258438, -0.14344751834869385, -0.5002943277359009, -0.2235780954360962, -0.05913449823856354, -0.3236725628376007, -0.1701442152261734, -0.5574647188186646, 0.7917976379394531, 0.40696030855178833, 0.2766154408454895, 0.520919919013977, 0.5255631804466248, -0.24873259663581848]\n",
      "<coroutine object BaseRagasEmbeddings.embed_text at 0x3097bece0>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "local_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"WhereIsAI/UAE-Large-V1\",\n",
    "    model_kwargs={\"device\": \"mps\"} # Or \"cuda\" for GPU, \"mps\" for Mac \n",
    ")\n",
    "local_embeddings = LangchainEmbeddingsWrapper(local_embeddings)\n",
    "\n",
    "res = local_embeddings.embed_query(\"Who is this?\")  # Test local embedding model\n",
    "print(res)\n",
    "\n",
    "res = local_embeddings.embed_text(\"Who is this?\")\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251cc400",
   "metadata": {},
   "source": [
    "# Default synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac392bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnowledgeGraph(nodes: 13, relationships: 0)\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset.transforms import (\n",
    "    default_transforms, \n",
    "    apply_transforms, \n",
    "    EmbeddingExtractor, \n",
    "    SummaryExtractor, \n",
    "    TitleExtractor,\n",
    "    HeadlinesExtractor,\n",
    "    HeadlineSplitter,\n",
    "    KeyphrasesExtractor,\n",
    "    HeadlineSplitter,\n",
    "    OverlapScoreBuilder,\n",
    ")\n",
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "\n",
    "# initialize your knowledge graph\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for chunk in all_processed_chunks:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": chunk.page_content, \"metadata\": chunk.metadata},\n",
    "        )\n",
    "    )\n",
    "print(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70d54a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984dcd6994104ef3890edc25d4b1b55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'headlines' already exists in node '7c0fe5'. Skipping!\n",
      "Property 'headlines' already exists in node '0dc2e0'. Skipping!\n",
      "Property 'headlines' already exists in node 'fde44f'. Skipping!\n",
      "Property 'headlines' already exists in node 'a0d61a'. Skipping!\n",
      "Property 'headlines' already exists in node '469e64'. Skipping!\n",
      "Property 'headlines' already exists in node 'bd6a12'. Skipping!\n",
      "Property 'headlines' already exists in node 'c5e01c'. Skipping!\n",
      "Property 'headlines' already exists in node '25fd44'. Skipping!\n",
      "Property 'headlines' already exists in node 'bfeff3'. Skipping!\n",
      "Property 'headlines' already exists in node 'ef0551'. Skipping!\n",
      "Property 'headlines' already exists in node '1019b3'. Skipping!\n",
      "Property 'headlines' already exists in node '6148ee'. Skipping!\n",
      "Property 'headlines' already exists in node '0239dd'. Skipping!\n"
     ]
    }
   ],
   "source": [
    "# headline extractor\n",
    "headline_extractor = HeadlinesExtractor(llm=llm)\n",
    "apply_transforms(kg, headline_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "074e15eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "KnowledgeGraph(nodes: 13, relationships: 0)\n",
      "Applying transform: HeadlinesExtractor(name='HeadlinesExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x35075b100>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='headlines', prompt=HeadlinesExtractorPrompt(instruction=Extract the most important max_num headlines from the given text that can be used to split the text into independent sections.Focus on Level 2 and Level 3 headings., examples=[(TextWithExtractionLimit(text='                Introduction\\n                Overview of the topic...\\n\\n                Main Concepts\\n                Explanation of core ideas...\\n\\n                Detailed Analysis\\n                Techniques and methods for analysis...\\n\\n                Subsection: Specialized Techniques\\n                Further details on specialized techniques...\\n\\n                Future Directions\\n                Insights into upcoming trends...\\n\\n                Subsection: Next Steps in Research\\n                Discussion of new areas of study...\\n\\n                Conclusion\\n                Final remarks and summary.\\n                ', max_num=6), Headlines(headlines=['Introduction', 'Main Concepts', 'Detailed Analysis', 'Subsection: Specialized Techniques', 'Future Directions', 'Conclusion']))], language=english), max_num=5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5a647890b14001b7b5fba73ea8e38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'headlines' already exists in node '25fd44'. Skipping!\n",
      "Property 'headlines' already exists in node 'bd6a12'. Skipping!\n",
      "Property 'headlines' already exists in node 'a0d61a'. Skipping!\n",
      "Property 'headlines' already exists in node '1019b3'. Skipping!\n",
      "Property 'headlines' already exists in node '0239dd'. Skipping!\n",
      "Property 'headlines' already exists in node '7c0fe5'. Skipping!\n",
      "Property 'headlines' already exists in node '469e64'. Skipping!\n",
      "Property 'headlines' already exists in node '0dc2e0'. Skipping!\n",
      "Property 'headlines' already exists in node 'c5e01c'. Skipping!\n",
      "Property 'headlines' already exists in node 'bfeff3'. Skipping!\n",
      "Property 'headlines' already exists in node 'fde44f'. Skipping!\n",
      "Property 'headlines' already exists in node '6148ee'. Skipping!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transform: HeadlineSplitter(name='HeadlineSplitter', filter_nodes=<function default_filter at 0x3097f7380>, min_tokens=500, max_tokens=1000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8197c9d8e2640d28b64f54451725c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transform: SummaryExtractor(name='SummaryExtractor', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x1314ebe20>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), merge_if_possible=True, max_token_limit=32000, tokenizer=<Encoding 'o200k_base'>, property_name='summary', prompt=SummaryExtractorPrompt(instruction=Summarize the given text in less than 10 sentences., examples=[(StringIO(text='Artificial intelligence\\n\\nArtificial intelligence is transforming various industries by automating tasks that previously required human intelligence. From healthcare to finance, AI is being used to analyze vast amounts of data quickly and accurately. This technology is also driving innovations in areas like self-driving cars and personalized recommendations.'), StringIO(text='AI is revolutionizing industries by automating tasks, analyzing data, and driving innovations like self-driving cars and personalized recommendations.'))], language=english))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3727acec543342579ed42d9e2071065a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transform: CustomNodeFilter(name='CustomNodeFilter', filter_nodes=<function default_transforms.<locals>.<lambda> at 0x350771f80>, llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), scoring_prompt=QuestionPotentialPrompt(instruction=Given a document summary and node content, score the content of the node in 1 to 5 range., examples=[], language=english), min_score=2, rubrics={'score1_description': 'The page content is irrelevant or does not align with the main themes or topics of the document summary.', 'score2_description': \"The page content partially aligns with the document summary, but it includes unrelated details or lacks critical information related to the document's main themes.\", 'score3_description': 'The page content generally reflects the document summary but may miss key details or lack depth in addressing the main themes.', 'score4_description': 'The page content aligns well with the document summary, covering the main themes and topics with minor gaps or minimal unrelated information.', 'score5_description': \"The page content is highly relevant, accurate, and directly reflects the main themes of the document summary, covering all important details and adding depth to the understanding of the document's topics.\"})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3636bfe64e2417f82815e06e7e01541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transform: <ragas.testset.transforms.engine.Parallel object at 0x357c829f0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc36d35a6a5f443b867bd442da59f114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transform: <ragas.testset.transforms.engine.Parallel object at 0x35671fd40>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088d0ad74a6f4d5b8515f8b106f6e02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After\n",
      "KnowledgeGraph(nodes: 45, relationships: 114)\n"
     ]
    }
   ],
   "source": [
    "# get all the default transforms as well\n",
    "print(\"Before\")\n",
    "print(kg)\n",
    "trans = default_transforms(documents=docs, llm=llm, embedding_model=local_embeddings)\n",
    "for tran in trans:\n",
    "    print(f\"Applying transform: {tran}\")\n",
    "    apply_transforms(kg, tran)\n",
    "print(\"After\")\n",
    "print(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3a0bf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(id: bfeff3, type: NodeType.DOCUMENT, properties: ['page_content', 'metadata', 'headlines', 'summary', 'summary_embedding'])\n"
     ]
    }
   ],
   "source": [
    "print(kg.nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_extractor = SummaryExtractor(llm=llm)\n",
    "apply_transforms(kg, summary_extractor)\n",
    "print(\"Summary extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_extractor = TitleExtractor(llm=llm)\n",
    "apply_transforms(kg, title_extractor)\n",
    "print(\"Title extraction complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrases_extractor = KeyphrasesExtractor(llm=llm)\n",
    "apply_transforms(kg, keyphrases_extractor)\n",
    "print(\"Keyphrases extraction complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd287d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary embeddings required by automatic persona generator\n",
    "summary_embedding_extractor = EmbeddingExtractor(embedding_model=local_embeddings,\n",
    "                                         property_name=\"summary_embedding\",\n",
    "                                         embed_property_name=\"summary\")\n",
    "apply_transforms(kg, summary_embedding_extractor)\n",
    "print(\"Embedding extraction complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regular embeddings\n",
    "regular_embedding_extractor = EmbeddingExtractor(\n",
    "    embedding_model=local_embeddings,\n",
    ")\n",
    "apply_transforms(kg, regular_embedding_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headline extractor\n",
    "headline_extractor = HeadlinesExtractor(llm=llm)\n",
    "apply_transforms(kg, headline_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms import ( \n",
    "    CosineSimilarityBuilder,\n",
    ")\n",
    "print(\"Before\")\n",
    "print(kg)\n",
    "cosine_similarity_builder = CosineSimilarityBuilder(threshold=0.5)\n",
    "apply_transforms(kg, cosine_similarity_builder)\n",
    "print(\"After\")\n",
    "print(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms import ( \n",
    "    OverlapScoreBuilder,\n",
    ")\n",
    "\n",
    "print(f\"Before\")\n",
    "print(kg)\n",
    "overlap_score_builder = OverlapScoreBuilder(property_name=\"keyphrases\", \n",
    "                                            threshold=0.3)\n",
    "apply_transforms(kg, overlap_score_builder)\n",
    "print(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the default transforms as well\n",
    "print(\"Before\")\n",
    "print(kg)\n",
    "trans = default_transforms(documents=docs, llm=llm, embedding_model=local_embeddings)\n",
    "apply_transforms(kg, trans)\n",
    "print(\"After\")\n",
    "print(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd1e47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Knowledge Graph Debug Info ===\n",
      "Total nodes: 45\n",
      "Total relationships: 114\n",
      "Relationship types found: {'entities_overlap', 'cosine_similarity', 'next', 'child'}\n"
     ]
    }
   ],
   "source": [
    "# Add this debugging code to see what relationships exist\n",
    "print(\"=== Knowledge Graph Debug Info ===\")\n",
    "print(f\"Total nodes: {len(kg.nodes)}\")\n",
    "print(f\"Total relationships: {len(kg.relationships)}\")\n",
    "\n",
    "# Check relationship types\n",
    "rel_types = set()\n",
    "for rel in kg.relationships:\n",
    "    rel_types.add(rel.type)\n",
    "    \n",
    "print(f\"Relationship types found: {rel_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41592f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ee375d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ac6553142248efbdc9b20641a171ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfe8c8a51224895b0787f188903e221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aadf6d82f8e414c9d396e8e8d243f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How Rise Connect help innovators in finance se...</td>\n",
       "      <td>[Data commercialisation\\n\\n\\n| Page | Title |\\...</td>\n",
       "      <td>Rise Connect provide platform for innovators t...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How has Open Banking contributed to innovation...</td>\n",
       "      <td>[\"\\n-\\n\\n\\nRise Insights report \\#HomeofFinTec...</td>\n",
       "      <td>Open Banking has enabled fintech companies to ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does rise.barclays approach the commercial...</td>\n",
       "      <td>[may find that customers grant them equal or g...</td>\n",
       "      <td>Rise.barclays finds that customers often grant...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What role did the University of Edinburgh play...</td>\n",
       "      <td>[The impact of data commerce\\n\\n\\nresilience t...</td>\n",
       "      <td>The University of Edinburgh established the De...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How data commercialisation help with data ethics?</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nrich-widmann-a816a54b\\n\\n\\n17 / ri...</td>\n",
       "      <td>Data commercialisation help with data ethics b...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How is Barclays ensuring the ethical use of AI...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nEthics in AI\\n\\n\\nDavid Bholat, Ba...</td>\n",
       "      <td>Barclays is ensuring the ethical use of AI in ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the key ethical considerations in AI ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nEthics in AI\\n\\n\\nDavid Bholat, Ba...</td>\n",
       "      <td>The key ethical considerations in AI include t...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How doe's artifical intelijence help investors...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nBanks, for example, would be able ...</td>\n",
       "      <td>Artificial Intelligence (AI) significantly enh...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What strategies can financial institutions use...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe risks of AI in investments\\n\\n...</td>\n",
       "      <td>Financial institutions can commercialize data ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What does Michael Payne believe about AI's pot...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nEthics in AI\\n\\n\\nDavid Bholat, Ba...</td>\n",
       "      <td>Michael Payne is excited about AI's mainstream...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What role does the Data Governance Act (DGA) p...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDo no harm: The ethical data dilem...</td>\n",
       "      <td>The Data Governance Act (DGA) plays a crucial ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How Rise Connect help fintech founder with dat...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nRise New York\\n\\n\\nCheers to a new...</td>\n",
       "      <td>Rise Connect, as a global digital platform, su...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How Rise Connect help innovators in finance se...   \n",
       "1   How has Open Banking contributed to innovation...   \n",
       "2   How does rise.barclays approach the commercial...   \n",
       "3   What role did the University of Edinburgh play...   \n",
       "4   How data commercialisation help with data ethics?   \n",
       "5   How is Barclays ensuring the ethical use of AI...   \n",
       "6   What are the key ethical considerations in AI ...   \n",
       "7   How doe's artifical intelijence help investors...   \n",
       "8   What strategies can financial institutions use...   \n",
       "9   What does Michael Payne believe about AI's pot...   \n",
       "10  What role does the Data Governance Act (DGA) p...   \n",
       "11  How Rise Connect help fintech founder with dat...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Data commercialisation\\n\\n\\n| Page | Title |\\...   \n",
       "1   [\"\\n-\\n\\n\\nRise Insights report \\#HomeofFinTec...   \n",
       "2   [may find that customers grant them equal or g...   \n",
       "3   [The impact of data commerce\\n\\n\\nresilience t...   \n",
       "4   [<1-hop>\\n\\nrich-widmann-a816a54b\\n\\n\\n17 / ri...   \n",
       "5   [<1-hop>\\n\\nEthics in AI\\n\\n\\nDavid Bholat, Ba...   \n",
       "6   [<1-hop>\\n\\nEthics in AI\\n\\n\\nDavid Bholat, Ba...   \n",
       "7   [<1-hop>\\n\\nBanks, for example, would be able ...   \n",
       "8   [<1-hop>\\n\\nThe risks of AI in investments\\n\\n...   \n",
       "9   [<1-hop>\\n\\nEthics in AI\\n\\n\\nDavid Bholat, Ba...   \n",
       "10  [<1-hop>\\n\\nDo no harm: The ethical data dilem...   \n",
       "11  [<1-hop>\\n\\nRise New York\\n\\n\\nCheers to a new...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   Rise Connect provide platform for innovators t...   \n",
       "1   Open Banking has enabled fintech companies to ...   \n",
       "2   Rise.barclays finds that customers often grant...   \n",
       "3   The University of Edinburgh established the De...   \n",
       "4   Data commercialisation help with data ethics b...   \n",
       "5   Barclays is ensuring the ethical use of AI in ...   \n",
       "6   The key ethical considerations in AI include t...   \n",
       "7   Artificial Intelligence (AI) significantly enh...   \n",
       "8   Financial institutions can commercialize data ...   \n",
       "9   Michael Payne is excited about AI's mainstream...   \n",
       "10  The Data Governance Act (DGA) plays a crucial ...   \n",
       "11  Rise Connect, as a global digital platform, su...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "\n",
    "generator = TestsetGenerator(llm=llm, embedding_model=local_embeddings, knowledge_graph=kg)\n",
    "query_distribution = default_query_distribution(llm)\n",
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce089a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_pd = testset.to_pandas()\n",
    "testset_pd.to_json('barclays_synthetic_multihop.json', orient='records', indent=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syftr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
